{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook shows how we implemented clustering using the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_building_data(group):\n",
    "    group = group.reset_index(level='ID')\n",
    "    # Specify columns explicitly for summing\n",
    "    resampled_group = group.resample('h').agg({'consumption': 'sum'})  # Example if 'consumption' is your numeric column\n",
    "    resampled_group['ID'] = group['ID'].iloc[0]  # Handle non-numeric separately if needed\n",
    "    resampled_group = resampled_group.set_index('ID', append=True)\n",
    "    return resampled_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path3 = '/kaggle/input/all-data/residential_all.pkl'\n",
    "df3 = pd.read_pickle(file_path3)\n",
    "#print(\"Data loaded\")\n",
    "df3[\"ID\"] = df3[\"ID\"].astype(\"category\")\n",
    "df3[\"time_code\"] = df3[\"time_code\"].astype(\"uint16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.set_index([\"date_time\",\"ID\"])\n",
    "df3 = df3.groupby('ID', group_keys=False, observed=True).apply(resample_building_data)\n",
    "df3=df3.reset_index(level=['ID',\"date_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the range of date_time values\n",
    "start_time = pd.Timestamp('2009-07-14 00:00:00')\n",
    "end_time = pd.Timestamp('2011-01-01 00:00:00')\n",
    "date_range = pd.date_range(start=start_time, end=end_time, freq='h')\n",
    "\n",
    "# Pivot the dataset\n",
    "df_pivoted = df3.pivot(index='ID', columns='date_time', values='consumption').reset_index()\n",
    "\n",
    "# Ensure columns are sorted by date_time\n",
    "# df_pivoted = df_pivoted.sort_index(axis=1)\n",
    "\n",
    "# Optional: Rename the columns to make them more readable\n",
    "df_pivoted.columns.name = None\n",
    "df_pivoted.columns = ['ID'] + [date.strftime('%Y-%m-%d %H:%M:%S') for date in date_range]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to calculate average energy used on each weekday\n",
    "def weekday_average(data):\n",
    "    weekday_avgs = data.groupby(data.index.weekday).mean() * 24\n",
    "    return weekday_avgs.values.flatten()\n",
    "\n",
    "# Function to calculate average energy used during different day segments\n",
    "def day_segment_average(data):\n",
    "    segments = {\n",
    "        'early_morning': (7, 9),\n",
    "        'morning': (9, 13),\n",
    "        'early_afternoon': (13, 17),\n",
    "        'late_afternoon': (17, 21),\n",
    "        'night': [(21, 24), (0, 7)]\n",
    "    }\n",
    "    averages = []\n",
    "    for segment, hours in segments.items():\n",
    "        if segment == 'night':\n",
    "            energy = data.between_time('21:00', '23:59').mean() * 10 + data.between_time('00:00', '06:59').mean() * 10\n",
    "        elif  segment == 'early_morning':\n",
    "            start, end = hours\n",
    "            energy = data.between_time(f'{start}:00', f'{end-1}:59').mean() * 2\n",
    "        else :\n",
    "            start, end = hours\n",
    "            energy = data.between_time(f'{start}:00', f'{end-1}:59').mean() * 4\n",
    "            \n",
    "        averages.append(energy)\n",
    "    return np.array(averages).flatten()\n",
    "\n",
    "# Function to calculate total energy used\n",
    "def total_energy_used(data):\n",
    "    return data.sum()\n",
    "\n",
    "# Function to calculate average energy used for different periods\n",
    "def average_energy_used(data):\n",
    "    hourly_avg = data.mean()\n",
    "    daily_avg = data.resample('D').sum().mean()\n",
    "    weekly_avg = data.resample('W').sum().mean()\n",
    "    monthly_avg = data.resample('ME').sum().mean()\n",
    "    return np.array([hourly_avg, daily_avg, weekly_avg, monthly_avg]).flatten()\n",
    "\n",
    "# Function to calculate average energy used on weekends and business days\n",
    "def weekend_businessday_avg(data):\n",
    "    weekends_avg = data[data.index.weekday >= 5].resample('D').sum().mean() \n",
    "    business_days_avg = data[data.index.weekday < 5].resample('D').sum().mean()\n",
    "    return np.array([weekends_avg, business_days_avg]).flatten()\n",
    "\n",
    "# Assuming df_pivoted is your pivoted DataFrame with 'ID' as the first column\n",
    "# Create a list to store the aggregation results\n",
    "aggregation_results = []\n",
    "\n",
    "for i, row in df_pivoted.iterrows():\n",
    "    building_data = row[1:].astype(float)  # Skip the first column (ID)\n",
    "    building_series = pd.Series(building_data.values, index=pd.date_range(start='2009-07-14 00:00:00', periods=len(building_data), freq='h'))\n",
    "    \n",
    "    # Perform the aggregations\n",
    "    weekday_avg = weekday_average(building_series)\n",
    "    segment_avg = day_segment_average(building_series)\n",
    "    total_energy = total_energy_used(building_series)\n",
    "    avg_energy = average_energy_used(building_series)\n",
    "    we_bd_avg = weekend_businessday_avg(building_series)\n",
    "    \n",
    "    # Combine all the aggregation results for the current building\n",
    "    aggregation_result = np.concatenate([weekday_avg, segment_avg, [total_energy], avg_energy, we_bd_avg])\n",
    "    aggregation_results.append(aggregation_result)\n",
    "\n",
    "# Define the columns for the aggregation results\n",
    "aggregation_columns = [\n",
    "    'avg_mon', 'avg_tue', 'avg_wed', 'avg_thu', 'avg_fri', 'avg_sat', 'avg_sun',\n",
    "    'avg_early_morning', 'avg_morning', 'avg_early_afternoon', 'avg_late_afternoon', 'avg_night',\n",
    "    'total_energy_used',\n",
    "    'hourly_avg_energy', 'daily_avg_energy', 'weekly_avg_energy', 'monthly_avg_energy',\n",
    "    'weekend_avg_energy', 'business_day_avg_energy'\n",
    "]\n",
    "\n",
    "# Convert the aggregation results to a DataFrame\n",
    "df_aggregations = pd.DataFrame(aggregation_results, columns=aggregation_columns)\n",
    "df_aggregations[\"business_day_avg_energy\"] = df_aggregations[\"avg_mon\"]+df_aggregations[\"avg_tue\"]+df_aggregations[\"avg_wed\"]+df_aggregations[\"avg_thu\"]+df_aggregations[\"avg_fri\"]\n",
    "df_aggregations[\"weekend_avg_energy\"] = df_aggregations[\"avg_sat\"]+df_aggregations[\"avg_sun\"]\n",
    "\n",
    "# Concatenate the original pivoted dataframe with the aggregations dataframe\n",
    "df_final = pd.concat([df_pivoted.reset_index(drop=True), df_aggregations], axis=1)\n",
    "\n",
    "# Display the final dataframe\n",
    "len(df_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(df_aggregations) \n",
    "\n",
    "# Apply PCA transformation\n",
    "pca = PCA(n_components=1)  # Keep 95% of the variance\n",
    "data_pca = pca.fit_transform(data_scaled)\n",
    "\n",
    "# Function to calculate WCSS for elbow method\n",
    "def calculate_wcss(data, max_k):\n",
    "    wcss = []\n",
    "    for k in range(1, max_k + 1):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        kmeans.fit(data)\n",
    "        wcss.append(kmeans.inertia_)\n",
    "    return wcss\n",
    "\n",
    "# Function to plot the elbow method\n",
    "def plot_elbow_method(wcss, max_k):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, max_k + 1), wcss, marker='o')\n",
    "    plt.title('Elbow Method for Optimal k')\n",
    "    plt.xlabel('Number of clusters (k)')\n",
    "    plt.ylabel('WCSS')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Set the maximum number of clusters to test\n",
    "max_k = 40\n",
    "\n",
    "# Calculate and plot elbow method\n",
    "wcss = calculate_wcss(data_pca, max_k)\n",
    "plot_elbow_method(wcss, max_k)\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "print(explained_variance_ratio)\n",
    "best_k_elbow = 3\n",
    "print(f'Best k according to elbow method: {best_k_elbow}')\n",
    "\n",
    "# Apply KMeans clustering\n",
    "final_kmeans = KMeans(n_clusters=best_k_elbow, random_state=42, n_init=90)\n",
    "final_kmeans.fit(data_pca)\n",
    "labels = final_kmeans.labels_\n",
    "\n",
    "# Calculate silhouette score\n",
    "silhouette = silhouette_score(data_pca, labels)\n",
    "print(\"Silhouette score for the KMeans model is \", silhouette)\n",
    "\n",
    "# Calculate Davies-Bouldin score\n",
    "dbs = davies_bouldin_score(data_pca, labels)\n",
    "print(\"Davies-Bouldin score for the KMeans model is \", dbs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Apply t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=30, n_iter=300, random_state=42)\n",
    "tsne_results = tsne.fit_transform(data_scaled)\n",
    "\n",
    "# Create a DataFrame with t-SNE results and cluster labels\n",
    "tsne_df = pd.DataFrame({\n",
    "    't-SNE1': tsne_results[:, 0],\n",
    "    't-SNE2': tsne_results[:, 1],\n",
    "    'Cluster': labels\n",
    "})\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(tsne_df['t-SNE1'], tsne_df['t-SNE2'], c=tsne_df['Cluster'], cmap='viridis', s=50)\n",
    "plt.title('t-SNE Plot of Building Energy Consumption Clusters')\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=set(labels))\n",
    "plt.colorbar(scatter, label='Cluster Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.DataFrame(labels, columns=['labels'])\n",
    "df_interpret = pd.concat([df_aggregations, df_labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many buildings in each cluster\n",
    "df_interpret[\"labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interpreting the results of first cluster\n",
    "df_interpret[df_interpret[\"labels\"] == 0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interpreting the results of third cluster\n",
    "df_interpret[df_interpret[\"labels\"] == 2].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interpreting the results of second cluster\n",
    "df_interpret[df_interpret[\"labels\"] == 1].describe()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5412774,
     "sourceId": 8987423,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
