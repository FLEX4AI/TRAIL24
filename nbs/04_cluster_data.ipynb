{
 "cells": [
  {
   "cell_type": "raw",
   "id": "cbe2ba79-2dfb-49ef-b756-39ed625a28ed",
   "metadata": {},
   "source": [
    "---\n",
    "description: Cluster Data \n",
    "output-file: cluster_data.html\n",
    "title: Cluster Data\n",
    "skip_showdoc: true\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad80153",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-03 17:18:32.803754: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-03 17:18:32.957056: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-03 17:18:32.957095: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-03 17:18:32.979028: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-03 17:18:33.027730: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-03 17:18:33.745999: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import umap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a67d762",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TRAIL24.data.preprocess import *\n",
    "from TRAIL24.data.cluster import *\n",
    "\n",
    "path_to_folder = '/home/vincent/Documents/Multitel/Projects/TRAIL_workshop_Portugal/project/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fcc6df",
   "metadata": {},
   "source": [
    "### Read the data and form the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205a7a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path3 = path_to_folder + 'TRAIL24/dataset_electricity/residential_all.pkl'\n",
    "df3 = pd.read_pickle(file_path3)\n",
    "df3[\"ID\"] = df3[\"ID\"].astype(\"category\")\n",
    "df3[\"time_code\"] = df3[\"time_code\"].astype(\"uint16\")\n",
    "\n",
    "df3 = df3.set_index([\"date_time\",\"ID\"])\n",
    "df3 = df3.groupby('ID', group_keys=False, observed=True).apply(resample_building_data)\n",
    "df3=df3.reset_index(level=['ID',\"date_time\"])\n",
    "\n",
    "# Generate the range of date_time values\n",
    "start_time = pd.Timestamp('2009-07-14 00:00:00')\n",
    "end_time = pd.Timestamp('2011-01-01 00:00:00')\n",
    "date_range = pd.date_range(start=start_time, end=end_time, freq='h')\n",
    "\n",
    "# Pivot the dataset\n",
    "df_pivoted = df3.pivot(index='ID', columns='date_time', values='consumption').reset_index()\n",
    "\n",
    "# Ensure columns are sorted by date_time\n",
    "# df_pivoted = df_pivoted.sort_index(axis=1)\n",
    "\n",
    "# Optional: Rename the columns to make them more readable\n",
    "df_pivoted.columns.name = None\n",
    "df_pivoted.columns = ['ID'] + [date.strftime('%Y-%m-%d %H:%M:%S') for date in date_range]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ac525b",
   "metadata": {},
   "source": [
    "### Compute summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83c5aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation_results = []\n",
    "\n",
    "for i, row in tqdm(df_pivoted.iterrows()):\n",
    "    building_data = row[1:].astype(float)  # Skip the first column (ID)\n",
    "    building_series = pd.Series(building_data.values, index=pd.date_range(start='2009-07-14 00:00:00', periods=len(building_data), freq='h'))\n",
    "    \n",
    "    # Perform the aggregations\n",
    "    #stats = weekly_monthly_statistics(building_series)\n",
    "    \n",
    "    stats = np.concatenate([compute_statistics(building_series)])\n",
    "    \n",
    "    # Combine all the aggregation results for the current building\n",
    "    aggregation_results.append(stats)\n",
    "    \n",
    "    \n",
    "# Convert the aggregation results to a DataFrame\n",
    "df_aggregations = pd.DataFrame(aggregation_results)#, columns=aggregation_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e499a2",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943f039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(df_aggregations.fillna(0))\n",
    "\n",
    "indexes = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "data_scaled_bis = data_scaled[:,indexes]\n",
    "\n",
    "spectral = SpectralClustering(n_clusters=3, affinity='nearest_neighbors', n_neighbors=10, random_state=42)\n",
    "labels = spectral.fit_predict(data_scaled_bis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ad4b7a",
   "metadata": {},
   "source": [
    "### Plot clustering results using UMAP and t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9193d896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply t-SNE\n",
    "tsne = TSNE(n_components=3, perplexity=30, learning_rate=500 , n_iter=1000, random_state=42)\n",
    "tsne_results = tsne.fit_transform(data_scaled_bis)\n",
    "\n",
    "# Create a DataFrame with t-SNE results and cluster labels\n",
    "tsne_df = pd.DataFrame({\n",
    "    't-SNE1': tsne_results[:, 0],\n",
    "    't-SNE2': tsne_results[:, 1],\n",
    "    't-SNE3': tsne_results[:, 2],\n",
    "    'Cluster': labels\n",
    "})\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(tsne_df['t-SNE1'], tsne_df['t-SNE2'], c=tsne_df['Cluster'], cmap='viridis', s=50)\n",
    "plt.title('t-SNE Plot of Building Energy Consumption Clusters')\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=set(labels))\n",
    "plt.colorbar(scatter, label='Cluster Label')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "# Plotting with Plotly\n",
    "plt.figure(figsize=(15,15))\n",
    "fig = px.scatter_3d(tsne_df, x='t-SNE1', y='t-SNE2', z='t-SNE3', color='Cluster',\n",
    "                    labels={'t-SNE1': 't-SNE Dimension 1', 't-SNE2': 't-SNE Dimension 2', 't-SNE3': 't-SNE Dimension 3'},\n",
    "                    color_continuous_scale='Viridis')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946509e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply UMAP for 2D visualization\n",
    "umap_2d = umap.UMAP(n_components=2, random_state=42)\n",
    "umap_results_2d = umap_2d.fit_transform(data_scaled_bis)\n",
    "\n",
    "# Apply UMAP for 3D visualization\n",
    "umap_3d = umap.UMAP(n_components=3, random_state=42)\n",
    "umap_results_3d = umap_3d.fit_transform(data_scaled_bis)\n",
    "\n",
    "# Create DataFrames with UMAP results and K-means cluster labels\n",
    "umap_df_2d = pd.DataFrame({\n",
    "    'UMAP1': umap_results_2d[:, 0],\n",
    "    'UMAP2': umap_results_2d[:, 1],\n",
    "    'Cluster': labels\n",
    "})\n",
    "\n",
    "umap_df_3d = pd.DataFrame({\n",
    "    'UMAP1': umap_results_3d[:, 0],\n",
    "    'UMAP2': umap_results_3d[:, 1],\n",
    "    'UMAP3': umap_results_3d[:, 2],\n",
    "    'Cluster': labels\n",
    "})\n",
    "\n",
    "# 2D Plotting with Matplotlib\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(umap_df_2d['UMAP1'], umap_df_2d['UMAP2'], c=umap_df_2d['Cluster'], cmap='viridis', s=50)\n",
    "plt.title('UMAP 2D Plot of K-means Clusters')\n",
    "plt.xlabel('UMAP Dimension 1')\n",
    "plt.ylabel('UMAP Dimension 2')\n",
    "plt.colorbar(scatter, label='Cluster Label')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# 3D Plotting with Plotly\n",
    "fig = px.scatter_3d(umap_df_3d, x='UMAP1', y='UMAP2', z='UMAP3', color='Cluster',\n",
    "                    title='UMAP 3D Plot of K-means Clusters',\n",
    "                    labels={'UMAP1': 'UMAP Dimension 1', 'UMAP2': 'UMAP Dimension 2', 'UMAP3': 'UMAP Dimension 3'},\n",
    "                    color_continuous_scale='Viridis')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a43a218",
   "metadata": {},
   "source": [
    "### Verify clustering by checking the timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ac8a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First cluster\n",
    "\n",
    "start = 10\n",
    "start_week = 168*10\n",
    "weeklength = 168*4\n",
    "\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.plot(df_pivoted.loc[revert_umap_projection_2D(0.0, 0.0)][1+start_week:start_week+weeklength+1].values, alpha=0.5)\n",
    "plt.plot(df_pivoted.loc[revert_umap_projection_2D(-2.5, 2.0)][1+start_week:start_week+weeklength+1].values, alpha=0.5)\n",
    "plt.plot(df_pivoted.loc[revert_umap_projection_2D(-2.5, -2.0)][1+start_week:start_week+weeklength+1].values, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af25852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second cluster\n",
    "\n",
    "start = 10\n",
    "start_week = 168*10\n",
    "weeklength = 168*4\n",
    "\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.plot(df_pivoted.loc[revert_umap_projection_2D(3.0, 14.0)][1+start_week:start_week+weeklength+1].values, alpha=0.5)\n",
    "plt.plot(df_pivoted.loc[revert_umap_projection_2D(2.0, 15.0)][1+start_week:start_week+weeklength+1].values, alpha=0.5)\n",
    "plt.plot(df_pivoted.loc[revert_umap_projection_2D(1.0, 13.5)][1+start_week:start_week+weeklength+1].values, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb18eb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third cluster\n",
    "\n",
    "start = 10\n",
    "start_week = 168*10\n",
    "weeklength = 168*4\n",
    "\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.plot(df_pivoted.loc[revert_umap_projection_2D(0.0, 9.0)][1+start_week:start_week+weeklength+1].values, alpha=0.5)\n",
    "plt.plot(df_pivoted.loc[revert_umap_projection_2D(1.0, 9.5)][1+start_week:start_week+weeklength+1].values, alpha=0.5)\n",
    "plt.plot(df_pivoted.loc[revert_umap_projection_2D(1.25, 8.75)][1+start_week:start_week+weeklength+1].values, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927d0fc8",
   "metadata": {},
   "source": [
    "### Save the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022be6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the rows of the initial dataframe for each cluster\n",
    "\n",
    "umap_df_2d = pd.DataFrame({\n",
    "    'UMAP1': umap_results_2d[:, 0],\n",
    "    'UMAP2': umap_results_2d[:, 1],\n",
    "    'Cluster': labels\n",
    "})\n",
    "\n",
    "\n",
    "cluster_0 = []\n",
    "cluster_1 = []\n",
    "cluster_2 = []\n",
    "\n",
    "\n",
    "for i,j,k in tqdm(zip(umap_results_2d[:,0], umap_results_2d[:,1], labels)):\n",
    "    \n",
    "    index = revert_umap_projection_2D(i, j)\n",
    "    \n",
    "    if(k==0):\n",
    "        cluster_0.append(index)\n",
    "        \n",
    "    elif(k==1):\n",
    "        cluster_1.append(index)\n",
    "        \n",
    "    else:\n",
    "        cluster_2.append(index)\n",
    "\n",
    "        \n",
    "# Print the number of samples for each cluster\n",
    "print(len(cluster_0), len(cluster_1), len(cluster_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28097280",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.save(path_to_folder+'TRAIL24/centralized experiments/cluster_0.npy', np.array(cluster_0))\n",
    "\n",
    "np.save(path_to_folder+'TRAIL24/centralized experiments/cluster_1.npy', np.array(cluster_1))\n",
    "\n",
    "np.save(path_to_folder+'TRAIL24/centralized experiments/cluster_2.npy', np.array(cluster_2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d726a3c6",
   "metadata": {},
   "source": [
    "### Feature importance analysis using XGBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbf732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_scaled_bis, labels, test_size=0.2, random_state=25)\n",
    "\n",
    "model = XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1)\n",
    "#model = XGBRegressor(n_estimators=500, max_depth=5, eta=0.05)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d134e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_plots = ['Mean', 'Std Dev', 'Skewness', 'Kurtosis', 'Energy', 'Periodicity', \n",
    "                'Trend', 'Seasonality', 'Stationarity', 'Autocor', 'Partial_Autocor']\n",
    "\n",
    "labels_plots_bis = np.array(labels_plots)[indexes]\n",
    "\n",
    "\n",
    "feature_importance = model.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.barh(range(len(sorted_idx)), feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(range(len(sorted_idx)), np.array(labels_plots_bis)[sorted_idx])\n",
    "plt.title('Feature Importance')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeedc06e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87af72c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
