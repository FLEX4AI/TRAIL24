{
 "cells": [
  {
   "cell_type": "raw",
   "id": "02ea8b3d-3c1c-4271-94d4-88d82e9c98d3",
   "metadata": {},
   "source": [
    "---\n",
    "description: Pruning methods\n",
    "output-file: compression.pruning.html\n",
    "title: Pruning\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55764bd8-7e6e-44d6-9eac-7f7757aea526",
   "metadata": {},
   "source": [
    "# compression.pruning\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c50cdf-dd83-4afa-9f4e-8192006beaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp compression.pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220b3588-6a2c-4b20-ac0e-e4f2208ce224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_pruning as tp\n",
    "from torch_pruning.pruner import function\n",
    "from fasterai.core.all import *\n",
    "\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "from onnxruntime import quantization\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from itertools import cycle\n",
    "from fastcore.basics import store_attr, listify, true\n",
    "from fasterbench.benchmark import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cfa5d5-b010-4556-a2d0-4635776c7928",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_ignored_layers(model):\n",
    "    ignored_layers = []\n",
    "\n",
    "    # Check and process trend blocks if they exist\n",
    "    if hasattr(model.ts_model, 'trend_blocks'):\n",
    "        for block in model.ts_model.trend_blocks:\n",
    "            if hasattr(block, 'backcast_fc'):\n",
    "                ignored_layers.append(block.backcast_fc)\n",
    "            if hasattr(block, 'forecast_fc'):\n",
    "                ignored_layers.append(block.forecast_fc)\n",
    "\n",
    "    # Check and process seasonality blocks if they exist\n",
    "    if hasattr(model.ts_model, 'seasonality_blocks'):\n",
    "        for block in model.ts_model.seasonality_blocks:\n",
    "            if hasattr(block, 'backcast_fc'):\n",
    "                ignored_layers.append(block.backcast_fc)\n",
    "            if hasattr(block, 'forecast_fc'):\n",
    "                ignored_layers.append(block.forecast_fc)\n",
    "\n",
    "    return ignored_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fd458e-dcc4-4594-b275-e82f9147fe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def adjust_layer_features(layer, pruning_ratio):\n",
    "    if hasattr(layer, 'in_features') and hasattr(layer, 'weight'):\n",
    "        in_features = layer.in_features\n",
    "        layer.in_features = int(in_features * (1-pruning_ratio))\n",
    "        local_scores = large_final(layer, 'column')\n",
    "        threshold = torch.quantile(local_scores.view(-1), pruning_ratio)\n",
    "        mask = local_scores.ge(threshold).to(dtype=local_scores.dtype)\n",
    "        ixs = torch.nonzero(mask[0] == 1, as_tuple=True)[0]\n",
    "        layer.weight.data = layer.weight[:, ixs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c2a524-2232-4136-a4d7-d27c63ccb430",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def prune_model(model, pruning_ratio, dummy_input):\n",
    "    imp = tp.importance.GroupNormImportance(p=2)\n",
    "    ignored_layers = get_ignored_layers(model)\n",
    "\n",
    "    pruner = tp.pruner.MetaPruner(\n",
    "        model.ts_model,\n",
    "        dummy_input,\n",
    "        importance=imp,\n",
    "        pruning_ratio=pruning_ratio, \n",
    "        ignored_layers=ignored_layers\n",
    "    )\n",
    "    pruner.step()\n",
    "    \n",
    "    if hasattr(model.ts_model, 'trend_blocks'):\n",
    "        for block in model.ts_model.trend_blocks:\n",
    "            for layer in [block.backcast_fc, block.forecast_fc]:\n",
    "                if layer is not None and layer.in_features != int(num_hidden*(1-pruning_ratio)):\n",
    "                    adjust_layer_features(layer, pruning_ratio)\n",
    "\n",
    "    if hasattr(model.ts_model, 'seasonality_blocks'):\n",
    "        for block in model.ts_model.seasonality_blocks:\n",
    "            for layer in [block.backcast_fc, block.forecast_fc]:\n",
    "                if layer is not None and layer.in_features != int(num_hidden*(1-pruning_ratio)):\n",
    "                    adjust_layer_features(layer, pruning_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f295df9-8bae-4762-9c54-a9697d3fe1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TRAIL24.models.nn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f0d18f-2991-4bc9-b7ac-a365f01be977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "input_size = 40  # Length of input time series\n",
    "output_size = 1  # Length of output time series (forecast)\n",
    "num_blocks = 12\n",
    "num_hidden = 512\n",
    "num_layers = 8\n",
    "embedding_dim = 10\n",
    "final_hidden = 512\n",
    "\n",
    "nbeats_params = {\n",
    "    'input_size': input_size,\n",
    "    'output_size': output_size,\n",
    "    'num_blocks': num_blocks,\n",
    "    'num_hidden': num_hidden,\n",
    "    'num_layers': num_layers\n",
    "}\n",
    "\n",
    "model_cfg = {\n",
    "    'model_type': 'nbeats', \n",
    "    'model_params': nbeats_params, \n",
    "    'embedding_dim': 10, \n",
    "    'final_hidden': 256\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1b4de9-14c9-4310-aab7-de375aacdacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = create_model(**model_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91709d5f-4f72-43f9-852c-c2d3cf59e135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Size: 90.39 MB (disk), 22576523 parameters\n"
     ]
    }
   ],
   "source": [
    "num_parameters = get_num_parameters(net)\n",
    "disk_size = get_model_size(net)\n",
    "print(f\"Model Size: {disk_size / 1e6:.2f} MB (disk), {num_parameters} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f037e473-a3a9-40d0-9a62-4b89d1264c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "num_features = 40\n",
    "\n",
    "features = torch.randn(batch_size, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc71dce6-e067-4b05-8e77-332681e7317c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 40])\n"
     ]
    }
   ],
   "source": [
    "prune_model(net, 0.3, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c034c8b4-f524-43b8-8793-eb526518a41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Size: 44.71 MB (disk), 11157731 parameters\n"
     ]
    }
   ],
   "source": [
    "num_parameters = get_num_parameters(net)\n",
    "disk_size = get_model_size(net)\n",
    "print(f\"Model Size: {disk_size / 1e6:.2f} MB (disk), {num_parameters} parameters\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
