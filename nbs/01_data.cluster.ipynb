{
 "cells": [
  {
   "cell_type": "raw",
   "id": "4c889502-01ba-4b8e-a33f-40d5c7d8e9dc",
   "metadata": {},
   "source": [
    "---\n",
    "description: Create a cluster module\n",
    "output-file: data.cluster.html\n",
    "title: Cluster\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c0009f-4b96-456c-9776-2e6aee9ed2f8",
   "metadata": {},
   "source": [
    "# data.cluster\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dd649d-d571-4bf2-ab1b-c28081aec603",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data.cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e152a0b5-6ebb-4798-a87d-adba80a7898b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e627e125-0e9f-4251-a334-375acf3fd969",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.fft import fft\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc6b663",
   "metadata": {},
   "source": [
    "`<<<<<<< HEAD`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb6670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def resample_building_data(group):\n",
    "    group = group.reset_index(level='ID')\n",
    "    # Specify columns explicitly for summing\n",
    "    resampled_group = group.resample('h').agg({'consumption': 'sum'})  # Example if 'consumption' is your numeric column\n",
    "    resampled_group['ID'] = group['ID'].iloc[0]  # Handle non-numeric separately if needed\n",
    "    resampled_group = resampled_group.set_index('ID', append=True)\n",
    "    \n",
    "    return resampled_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaad12fd-d60b-4f05-b370-2049067bad82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def calculate_wcss(data: list[float], # the input dataframe\n",
    "                   max_k: int # the number of clusters\n",
    "                  ) -> float:\n",
    "    \"compute the WCSS metric\"\n",
    "    wcss = []\n",
    "    for k in range(1, max_k + 1):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        kmeans.fit(data)\n",
    "        wcss.append(kmeans.inertia_)\n",
    "    return wcss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340025ba",
   "metadata": {},
   "source": [
    "`=======`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d69e53",
   "metadata": {},
   "source": [
    "`>>>>>>> origin/func_comments`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aab97b3-ee08-4fbf-9507-c615068f5662",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def plot_elbow_method(wcss:list[float], # the wcss metric to plot\n",
    "                      max_k:int # the number of clusters\n",
    "                     ):\n",
    "    \"plot the graph of the wcss metric as a function of the number of clusters\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, max_k + 1), wcss, marker='o')\n",
    "    plt.title('Elbow Method for Optimal k')\n",
    "    plt.xlabel('Number of clusters (k)')\n",
    "    plt.ylabel('WCSS')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3725bf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def compute_statistics(data: list[float] # the input dataframe\n",
    "                      ) -> tuple: # multiple outputs\n",
    "    \"compute multiple statistics like mean, std, skewness, kurtosis, etc\"\n",
    "    avg = data.mean()\n",
    "    std = data.std()\n",
    "    skw = skew(data)\n",
    "    krt = kurtosis(data)\n",
    "    \n",
    "    # Compute energy (sum of squared values)\n",
    "    energy = np.sum(data**2)\n",
    "    \n",
    "    # Compute periodicity using the dominant frequency from the Fourier Transform\n",
    "    fft_values = fft(np.array(data))\n",
    "    fft_magnitudes = np.abs(fft_values)\n",
    "    periodicity = np.argmax(fft_magnitudes[1:len(fft_magnitudes)//2]) + 1  # Dominant frequency index\n",
    "    \n",
    "     # Trend (using linear regression)\n",
    "    trend = np.polyfit(np.arange(len(data)), data, 1)[0]  # Slope of the trend\n",
    "\n",
    "    # Seasonality (using Fourier Transform)\n",
    "    seasonality = fft_magnitudes[1:len(fft_magnitudes)//2].max()  # Magnitude of the dominant frequency\n",
    "\n",
    "    # Stationarity (using Augmented Dickey-Fuller test)\n",
    "    adf_result = adfuller(data)\n",
    "    stationarity = adf_result[0]  # ADF statistic (more negative means more likely stationary)\n",
    "\n",
    "    # Autocorrelation (first lag)\n",
    "    autocorr = acf(data, nlags=1)[1]  # ACF for the first lag\n",
    "\n",
    "    # Partial Autocorrelation (first lag)\n",
    "    partial_autocorr = pacf(data, nlags=1)[1]  # PACF for the first lag\n",
    "    \n",
    "    \n",
    "    return avg, std, skw, krt, energy, periodicity, trend, seasonality, stationarity, autocorr, partial_autocorr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f935642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def weekly_monthly_statistics(data: pd.Series\n",
    "                             ) -> np.ndarray:\n",
    "    \"Compute some statistics (mean, std, skewness, kurtosis, energy, periodicity)\"\n",
    "    \n",
    "    avgs, stds, skws, krts, energies, periodicities, trends, seasonalities, stationarities, autocorrs, partial_autocorrs = [], [], [], [], [], [], [], [], [], [], []\n",
    "    \n",
    "    weeklength = 168*4  # Weekly data length (assuming hourly data)\n",
    "    \n",
    "    for i in np.arange(0, len(data)-weeklength, weeklength):\n",
    "        avg, std, skw, krt, energy, periodicity, trend, seasonality, stationarity, autocorr, partial_autocorr = compute_statistics(data[i:i+weeklength])\n",
    "        \n",
    "        avgs.append(avg)\n",
    "        stds.append(std)\n",
    "        skws.append(skw)\n",
    "        krts.append(krt)\n",
    "        energies.append(energy)\n",
    "        periodicities.append(periodicity)\n",
    "        trends.append(trend)\n",
    "        seasonalities.append(seasonality)\n",
    "        stationarities.append(stationarity)\n",
    "        autocorrs.append(autocorrs)\n",
    "        partial_autocorrs.append(partial_autocorr)\n",
    "        \n",
    "    # Combine the statistics into a single array\n",
    "    weekly_stats = np.concatenate([avgs, stds, skws, krts, energies, periodicities, \n",
    "                                   trends, seasonalities, stationarities, autocorrs, partial_autocorrs])\n",
    "    \n",
    "    return weekly_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482e0715",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def revert_umap_projection_2D(umap_value_1:float, # first umap coeff\n",
    "                              umap_value_2:float # second umap coeff\n",
    "                             ) -> int:\n",
    "    \"Find the data that corresponds to the UMAP projection in 2D\"\n",
    "    \n",
    "    # Example: Find the original row corresponding to a specific UMAP projection\n",
    "    # Let's say you're looking for the closest point to [UMAP1_value, UMAP2_value]\n",
    "    UMAP1_value = umap_value_1\n",
    "    UMAP2_value = umap_value_2\n",
    "\n",
    "    # Calculate the Euclidean distance between the given UMAP values and all UMAP projections\n",
    "    distances = np.sqrt((umap_df_2d['UMAP1'] - UMAP1_value)**2 + (umap_df_2d['UMAP2'] - UMAP2_value)**2)\n",
    "\n",
    "    # Find the index of the minimum distance\n",
    "    min_distance_index = distances.idxmin()\n",
    "\n",
    "    return min_distance_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbaf7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def revert_umap_projection_3D(umap_value_1, # first umap coeff\n",
    "                              umap_value_2, # second umap coeff\n",
    "                              umap_value_3 # third umap coeff\n",
    "                             ) -> int:\n",
    "    \"Find the data that corresponds to the UMAP projection in 3D\"\n",
    "    \n",
    "    # Example: Find the original row corresponding to a specific UMAP projection\n",
    "    # Let's say you're looking for the closest point to [UMAP1_value, UMAP2_value]\n",
    "    UMAP1_value = umap_value_1\n",
    "    UMAP2_value = umap_value_2\n",
    "    UMAP3_value = umap_value_3\n",
    "\n",
    "    # Calculate the Euclidean distance between the given UMAP values and all UMAP projections\n",
    "    distances = np.sqrt(\n",
    "                            (umap_df_3d['UMAP1'] - UMAP1_value)**2 + \n",
    "                            (umap_df_3d['UMAP2'] - UMAP2_value)**2 + \n",
    "                            (umap_df_3d['UMAP3'] - UMAP3_value)**2\n",
    "                        )\n",
    "\n",
    "    # Find the index of the minimum distance\n",
    "    min_distance_index = distances.idxmin()\n",
    "\n",
    "    return min_distance_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9fe9fa-9114-4b61-bd8a-b0df6e6c83a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eddd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
