{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook trains NHITS model on ten building only. \"all-data\" contains the data of all the buildings in the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T16:03:52.326203Z",
     "iopub.status.busy": "2024-07-23T16:03:52.325833Z",
     "iopub.status.idle": "2024-07-23T16:03:52.339263Z",
     "shell.execute_reply": "2024-07-23T16:03:52.338349Z",
     "shell.execute_reply.started": "2024-07-23T16:03:52.326173Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torchmetrics import MeanSquaredError,SymmetricMeanAbsolutePercentageError\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "from memory_profiler import memory_usage\n",
    "import resource\n",
    "import pickle\n",
    "\n",
    "def get_memory_usage():\n",
    "    # Return current memory usage in MB\n",
    "    return resource.getrusage(resource.RUSAGE_SELF).ru_maxrss / 1024\n",
    "\n",
    "class NHiTSBlock(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_hidden, num_layers):\n",
    "        super(NHiTSBlock, self).__init__()\n",
    "        self.hidden = nn.ModuleList([nn.Linear(input_size, num_hidden)] +\n",
    "                                    [nn.Linear(num_hidden, num_hidden) for _ in range(num_layers - 1)])\n",
    "        self.theta_b = nn.Linear(num_hidden, input_size)\n",
    "        self.theta_f = nn.Linear(num_hidden, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.hidden:\n",
    "            x = torch.relu(layer(x))\n",
    "        backcast = self.theta_b(x)\n",
    "        forecast = self.theta_f(x)\n",
    "        return backcast, forecast\n",
    "\n",
    "class NHiTS(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_blocks, num_hidden, num_layers):\n",
    "        super(NHiTS, self).__init__()\n",
    "        self.blocks = nn.ModuleList([NHiTSBlock(input_size, output_size, num_hidden, num_layers) for _ in range(num_blocks)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        forecast = torch.zeros((x.size(0), self.blocks[0].theta_f.out_features), device=x.device)\n",
    "        for block in self.blocks:\n",
    "            backcast, block_forecast = block(x)\n",
    "            x = x - backcast\n",
    "            forecast = forecast + block_forecast\n",
    "        return forecast\n",
    "\n",
    "# Example usage:\n",
    "input_size = 10  # Length of input time series\n",
    "output_size = 1  # Length of output time series (forecast)\n",
    "num_blocks = 80\n",
    "num_hidden = 512\n",
    "num_layers = 20\n",
    "\n",
    "\n",
    "# Define a function to create the model for memory profiling\n",
    "def create_model():\n",
    "    model = NHiTS(input_size, output_size, num_blocks, num_hidden, num_layers)\n",
    "    return model\n",
    "\n",
    "start_mem = get_memory_usage()\n",
    "model = create_model()\n",
    "end_mem = get_memory_usage()\n",
    "print(f\"Memory used for model creation: {end_mem - start_mem} MB\")\n",
    "# Create the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "def sMAPE(outputs, targets):\n",
    "    \"\"\"\n",
    "    Symmetric Mean Absolute Percentage Error (sMAPE) for evaluating the model.\n",
    "    It is the sum of the absolute difference between the predicted and actual values divided by the average of\n",
    "    the predicted and actual value, therefore giving a percentage measuring the amount of error :\n",
    "    100/n * sum(|F_t - A_t| / ((|F_t| + |A_t|) / 2)) with t = 1 to n\n",
    "\n",
    "    :param outputs: predicted values\n",
    "    :param targets: real values\n",
    "    :return: sMAPE\n",
    "    \"\"\"\n",
    "    return 100 / len(targets) * torch.sum(\n",
    "        2 * torch.abs(outputs - targets) / (torch.abs(outputs) + torch.abs(targets))\n",
    "    )\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:i + seq_length]\n",
    "        y = data[i + seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "    return xs, ys\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "# Load and preprocess data\n",
    "\n",
    "file_path3 = '/kaggle/input/all-data/residential_all.pkl'\n",
    "df3 = pd.read_pickle(file_path3)\n",
    "print(\"Datra loaded\")\n",
    "df3=df3[df3[\"ID\"] <= 1050]\n",
    "df3[\"ID\"] = df3[\"ID\"].astype(\"category\")\n",
    "df3[\"time_code\"] = df3[\"time_code\"].astype(\"uint16\")\n",
    "df_test=df3[df3[\"ID\"] == 1003]\n",
    "scaler = MinMaxScaler()\n",
    "df3 = df3.set_index([\"date_time\",\"ID\"])\n",
    "df_test = df_test.set_index([\"date_time\",\"ID\"])\n",
    "df3['consumption'] = scaler.fit_transform(df3[['consumption']])\n",
    "df_test['consumption'] = scaler.transform(df_test[['consumption']])\n",
    "df3=df3[[\"consumption\"]]\n",
    "df_test=df_test[[\"consumption\"]]\n",
    "\n",
    "def resample_building_data(group):\n",
    "    group = group.reset_index(level='ID')\n",
    "    # Specify columns explicitly for summing\n",
    "    resampled_group = group.resample('h').agg({'consumption': 'sum'})  # Example if 'consumption' is your numeric column\n",
    "    resampled_group['ID'] = group['ID'].iloc[0]  # Handle non-numeric separately if needed\n",
    "    resampled_group = resampled_group.set_index('ID', append=True)\n",
    "    return resampled_group\n",
    "\n",
    "\n",
    "# Group by 'building_id' and resample each group's data\n",
    "df3 = df3.groupby('ID', group_keys=False, observed=True).apply(resample_building_data)\n",
    "df3 = df3.sort_index()\n",
    "df_test = df_test.groupby('ID', group_keys=False, observed=True).apply(resample_building_data)\n",
    "df_test = df_test.sort_index()\n",
    "\n",
    "device = \"cuda\"\n",
    "lr = 0.001\n",
    "n_epochs = 2\n",
    "window_size = 10\n",
    "\n",
    "train_data, train_labels = create_sequences(df3[\"2009-07-14\":\"2010-12-15\"].values, window_size)\n",
    "test_data, test_labels = create_sequences(df3[\"2010-12-15\":\"2011-01-01\"].values, window_size)\n",
    "sample_data, sample_labels = create_sequences(df_test[\"2010-12-15\":\"2011-01-01\"].values, window_size)\n",
    "\n",
    "train_dataset = Data(torch.FloatTensor(train_data), torch.FloatTensor(train_labels))\n",
    "test_dataset = Data(torch.FloatTensor(test_data), torch.FloatTensor(test_labels))\n",
    "sample_dataset = Data(torch.FloatTensor(sample_data), torch.FloatTensor(sample_labels))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=1024, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=1024)\n",
    "sample_loader = DataLoader(sample_dataset, shuffle=False, batch_size=1)\n",
    "\n",
    "def train_function(net, criterion, optimizer, train_loader, n_epochs=5, device=torch.device(\"cpu\")):\n",
    "    from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min',verbose =True ,threshold=0.1,patience=3,factor=0.5)\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "        counter = 0\n",
    "        for seqs, labels in train_loader:\n",
    "            counter+=1\n",
    "            seqs, labels = seqs.float().to(device), labels.float().to(device)\n",
    "            seqs = seqs.view(seqs.size(0), -1)  # Ensure the input shape matches the expected shape\n",
    "            outputs = net(seqs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            epoch_loss += loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if counter % 50 == 0:\n",
    "                print(f\"Batch Number {counter} {loss.item()}\")\n",
    "        scheduler.step(epoch_loss / counter) \n",
    "        print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
    "        with open(f'modelcheckpoint{epoch}.pickle', 'wb') as handle:\n",
    "            pickle.dump([net,optimizer], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    return net\n",
    "\n",
    "def test_function(net, dataloader_test, scaler, label_scaler, device=torch.device(\"cuda\"),return_data=False):\n",
    "    mse = MeanSquaredError().to(device)\n",
    "    smape = SymmetricMeanAbsolutePercentageError().to(device)\n",
    "    net.eval()\n",
    "    list_outputs = []\n",
    "    list_targets = []\n",
    "    with torch.no_grad():  #to not reservate a memory space for gradients\n",
    "        for seqs, labels in dataloader_test:\n",
    "            # Move data to device\n",
    "            seqs, labels = seqs.float().to(device), labels.float().to(device)\n",
    "            # Pass seqs to net and squeeze the result\n",
    "            seqs = seqs.view(seqs.size(0), -1)\n",
    "            outputs = net(seqs)\n",
    "\n",
    "            if label_scaler:\n",
    "                outputs = torch.tensor(scaler.inverse_transform(outputs),\n",
    "                                       device=device)\n",
    "                labels = torch.tensor(label_scaler.inverse_transform(labels),\n",
    "                                      device=device)\n",
    "\n",
    "            outputs = outputs.squeeze()\n",
    "            labels = labels.squeeze()\n",
    "\n",
    "            # Compute loss\n",
    "            mse(outputs, labels)\n",
    "            smape(outputs, labels)\n",
    "            list_targets.append(labels.detach()) #detach() to remove pytorch constraints on the values\n",
    "            list_outputs.append(outputs.detach())\n",
    "    test_mse = mse.compute()\n",
    "    test_smape = smape.compute()\n",
    "    print(f\"Test MSE: {test_mse} , SMAPE {test_smape}\")\n",
    "    if return_data:\n",
    "        return torch.tensor(list_outputs, device=device), torch.tensor(list_targets, device=device), test_mse\n",
    "\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "#with open('/kaggle/input/model1/modelcheckpoint1.pickle', 'rb') as handle:\n",
    "#    model, optimizer = pickle.load(handle)\n",
    "print(\"Model Started\")\n",
    "\n",
    "start_mem = get_memory_usage()\n",
    "time1=time.time()\n",
    "net = train_function(model,\n",
    "                        criterion,\n",
    "                        optimizer,\n",
    "                        train_loader,\n",
    "                        n_epochs=n_epochs,\n",
    "                        device=device)\n",
    "time2=time.time()\n",
    "print(\"training time is \",time2-time1)\n",
    "end_mem = get_memory_usage()\n",
    "print(f\"Memory used for model training: {end_mem - start_mem} MB\")\n",
    "\n",
    "\n",
    "\n",
    "net.to(\"cuda\")\n",
    "time3=time.time()\n",
    "# list_outputs, list_targets, test_mse = test_function(net, test_loader, None, None, torch.device(\"cuda\"))\n",
    "test_function(net, test_loader, None, None, torch.device(\"cuda\"))\n",
    "time4=time.time()\n",
    "print(\"inference time is \",time4-time3)\n",
    "\n",
    "# s_mape = round(sMAPE(list_outputs, list_targets).cpu().item(), 3)\n",
    "# print(f\"sMAPE: {s_mape}%\")\n",
    "sample_outputs, sample_targets, sample_mse = test_function(net, sample_loader, None, None, torch.device(\"cuda\"),True)\n",
    "# Visualizations\n",
    "plt.plot(sample_outputs.to(\"cpu\"), \"-o\", color=\"blue\", label=\"N-BEATS Predictions\", markersize=3)\n",
    "plt.plot(sample_targets.to(\"cpu\"), color=\"red\", label=\"Actual\")\n",
    "plt.ylabel(\"Energy Consumption (MW)\")\n",
    "plt.title(f\"Energy Consumption for Electricity state building number 1003\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5387726,
     "sourceId": 8952485,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5394756,
     "sourceId": 8962797,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5412774,
     "sourceId": 8987423,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
