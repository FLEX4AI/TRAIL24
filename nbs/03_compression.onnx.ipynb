{
 "cells": [
  {
   "cell_type": "raw",
   "id": "406d9fec-435a-4f58-988b-f429fb86058c",
   "metadata": {},
   "source": [
    "---\n",
    "description: ONNX export\n",
    "output-file: compression.onnx.html\n",
    "title: ONNX\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b980613-daa0-492b-96c4-0f646a66669f",
   "metadata": {},
   "source": [
    "# compression.onnx\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b977cd-dd2c-4321-a612-128021291531",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp compression.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635707f2-ef07-4dcc-9c48-3553f51542b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dffb05-941f-4ce7-b23d-2bd595557fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def script_model(model, dummy_input, path='scripted_model.pt'):\n",
    "    scripted_model = torch.jit.trace(model, dummy_input)\n",
    "    scripted_model.save(path)\n",
    "    return scripted_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6fa31a-97b3-4b82-9a4b-338bedb9e83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def quantize_onnx(model, dummy_input, onnx_path=\"model.onnx\", quant_onnx_path=\"model_quantized.onnx\"):\n",
    "    torch.onnx.export(\n",
    "    model,              \n",
    "    dummy_input,        \n",
    "    onnx_path, \n",
    "    input_names=[\"features\", \"year\", \"month\", \"day\", \"hour\"],   \n",
    "    output_names=[\"output\"], \n",
    "    dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}}, \n",
    "    opset_version=11\n",
    "    )\n",
    "\n",
    "    quantize_dynamic(\n",
    "        onnx_path,\n",
    "        quant_onnx_path,\n",
    "        weight_type=QuantType.QUInt8\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d8ace1-a23c-46f2-8752-fbe8f9ec36f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TRAIL24.models.nn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46bbfc7-d8ff-41e7-934b-f28006b5dceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "input_size = 40  # Length of input time series\n",
    "output_size = 1  # Length of output time series (forecast)\n",
    "num_blocks = 12\n",
    "num_hidden = 512\n",
    "num_layers = 8\n",
    "embedding_dim = 10\n",
    "final_hidden = 512\n",
    "\n",
    "nbeats_params = {\n",
    "    'input_size': input_size,\n",
    "    'output_size': output_size,\n",
    "    'num_blocks': num_blocks,\n",
    "    'num_hidden': num_hidden,\n",
    "    'num_layers': num_layers\n",
    "}\n",
    "\n",
    "model_cfg = {\n",
    "    'model_type': 'nbeats', \n",
    "    'model_params': nbeats_params, \n",
    "    'embedding_dim': 10, \n",
    "    'final_hidden': 256\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3651b9-f1cd-420a-96e5-f1db739661d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = create_model(**model_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f9e151-938d-4896-85a9-4ba6f3934509",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "num_features = 40\n",
    "\n",
    "features = torch.randn(batch_size, num_features)\n",
    "month = torch.randint(0, 12, (batch_size, 1))      # Random months between 1 and 12\n",
    "day = torch.randint(0, 31, (batch_size, 1))        # Random days between 1 and 31\n",
    "hour = torch.randint(0, 24, (batch_size, 1))       # Random hours between 0 and 23\n",
    "\n",
    "example_input = features, month, day, hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391a4b9f-7b53-4307-8bcb-cbea49dcc436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 40])\n",
      "torch.Size([5, 40])\n",
      "torch.Size([5, 40])\n"
     ]
    }
   ],
   "source": [
    "scripted_model = script_model(net, example_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daa2ce4-956d-44b7-b57f-90198db32d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 40])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
     ]
    }
   ],
   "source": [
    "quantize_onnx(net, example_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
